

# **Platform Engineering for AI - Course Overview**

Welcome to the **Platform Engineering for AI** course! This program is designed to provide you with the essential skills needed to build, deploy, and manage AI applications using modern technologies like **Kubernetes**, **Docker**, **CI/CD pipelines**, and **GPU infrastructure**.

### **Course Highlights:**

* Master **DevOps** skills tailored for the AI-driven world
* Deploy and orchestrate AI applications like **LLaMA** and **DeepSeek**
* Gain hands-on experience with tools such as **Kubernetes**, **Docker**, and **CI/CD**
* Manage **AI infrastructure** and **GPU workflows** to optimize AI model training and inference
* Prepare for a career in the fast-evolving AI landscape

---

## **Course Curriculum:**

### **Introduction to Tech & AI Career**

* Overview of technology and the AI tech stack
* Mistakes to avoid in the tech job hunt
* Introduction to DevOps and how AI is changing the landscape

### **Software Development**

* Agile SDLC, Developer PC setup with Git and Visual Studio
* Python Coding
* Impact of AI on software development and the software lifecycle

### **Hardware and Networking**

* Deconstructing a computer, networking fundamentals, subnetting, DNS, and DHCP
* Introduction to Linux, Redhat Linux, commands, and file systems
* Networking fundamentals including IPv6, VPN, and cloud networking basics

### **Cloud Computing**

* Deep dive into **AWS**, **Azure**, and **GCP**
* Introduction to cloud services, EC2, S3, Lambda, and Google AI tools
* Setting up a virtual private cloud and Terraform for Infrastructure as Code (IaC)

### **DevOps & Automation**

* Introduction to **Docker** and **Kubernetes** for containerized applications
* CI/CD pipeline development with Jenkins and GitHub Actions
* Terraform projects, Ansible for automation, and setting up deployment pipelines

### **AI & Large Language Models (LLM)**

* Introduction to GPU architecture and its role in AI, including **Nvidia GPUs** and **Kubernetes Nvidia Operator**
* LLMOps lifecycle management, inference optimization, and cost control
* Deploying models like **LLaMA** on Nvidia GPUs, and understanding **LLMOps** for AI models

### **Advanced AI Platform Engineering**

* Site Reliability Engineering (SRE) for AI workloads
* Ensuring **scalability**, **high availability**, and **fault tolerance** for AI inference
* Observability and model-aware monitoring for AI platforms

### **Projects**

* **Deploying AI Applications**: Full cycle deployment of web apps, databases, and voting apps with **Kubernetes** and **AWS ECS**
* **LLMOps Projects**: Deploying a **DB-Agent** on cloud, optimizing **LLaMA** inference on Nvidia H100

### **Special Topics:**

* **AI Platform Engineering Careers**: How to adapt to AI and evolve your DevOps career with skills in **LLMOps** and **AI agents**
* **Observability and Logging for AI Cloud**: Infrastructure monitoring, traditional vs AI GPU cloud environments

---

## **Subscription Plans:**

[Signup Now](https://becloudready.teachable.com/p/ai-platform-engineer)

---



